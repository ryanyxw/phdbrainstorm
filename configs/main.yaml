ROOT_DIR: .

seed: 0 # DO NOT CHANGE THIS.

exp_name: "pubmed"

num_proc: 1

train:
  do: True
  model_path_or_name: "meta-llama/Meta-Llama-3-8B"
  out_directory: "test_output_models"

  wandb:
    do: False

  save_model: True

  max_seq_len: 512

  training_args:
    per_device_train_batch_size: 1
    gradient_accumulation_steps: 16
    num_train_epochs: 1
#    fp16: True
    learning_rate: 1e-5
    warmup_ratio: 0.03
    logging_steps: 2
    deepspeed: "configs/ds_config.json"


