ROOT_DIR: /root/ryanwang/phdbrainstorm

seed: 0 # DO NOT CHANGE THIS.

exp_name: "analyze_olmoe_orig"

num_proc: 1

get_logits:
  do: False

  #model_name_or_path: "${ROOT_DIR}/models/olmoe-pretrain-replicate/step30995-hf"
  model_name_or_path: "${ROOT_DIR}/models/olmoe-pretrain-mose-unbalanced-1012/step30995-hf"
  eval_folder: "${ROOT_DIR}/evals/weka_oe-training-default_ryanwang_phdbrainstorm_models_olmoe-pretrain-mose-unbalanced-1012_step30995-hf"

  batch_size: 16
  # array of dataesets to evaluate
  eval_datasets:
    - "gsm8k"
    - "coqa"
    - "triviaqa"
    - "drop"
#    - "squad"
    - "naturalqs_open"
    - "minerva_math_algebra"
    - "minerva_math_counting_and_probability"
    - "minerva_math_geometry"
#    - "minerva_math_intermediate_algebra"
    - "minerva_math_number_theory"
    - "minerva_math_prealgebra"
    - "minerva_math_precalculus"
#    - "bbh_boolean_expressions"
#    - "bbh_causal_judgement"
#    - "bbh_date_understanding"
#    - "bbh_disambiguation_qa"
#    - "bbh_dyck_languages"
#    - "bbh_formal_fallacies"
#    - "bbh_geometric_shapes"
#    - "bbh_hyperbaton"
#    - "bbh_logical_deduction_five_objects"
#    - "bbh_logical_deduction_seven_objects"
#    - "bbh_logical_deduction_three_objects"
#    - "bbh_movie_recommendation"
#    - "bbh_multistep_arithmetic_two"
#    - "bbh_navigate"
#    - "bbh_object_counting"
#    - "bbh_penguins_in_a_table"
#    - "bbh_reasoning_about_colored_objects"
#    - "bbh_ruin_names"
#    - "bbh_salient_translation_error_detection"
#    - "bbh_snarks"
#    - "bbh_sports_understanding"
#    - "bbh_temporal_sequences"
#    - "bbh_tracking_shuffled_objects_five_objects"
#    - "bbh_tracking_shuffled_objects_seven_objects"
#    - "bbh_tracking_shuffled_objects_three_objects"
#    - "bbh_web_of_lies"
#    - "bbh_word_sorting"

#    - "mbpp"
#    - "mbppplus"
#    - "codex_humaneval"
#    - "codex_humanevalplus"
#    - "agi_eval_english_1shot"

analyze_domain_specialization:
  do: True

  eval_folder: "${ROOT_DIR}/evals/weka_oe-training-default_ryanwang_phdbrainstorm_models_olmoe-pretrain-mose-unbalanced-1012_step30995-hf"
  plot_folder: "${ROOT_DIR}/plots"

  k: 8

  correct_only: True
  
  eval_datasets:
    - "gsm8k"
    - "coqa"
    - "triviaqa"
    - "drop"
    - "naturalqs_open"
    - "minerva_math_algebra"
    - "minerva_math_counting_and_probability"
    - "minerva_math_geometry"
    - "minerva_math_number_theory"
    - "minerva_math_prealgebra"
    - "minerva_math_precalculus"