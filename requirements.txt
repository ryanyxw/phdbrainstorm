torch==2.6.0
omegaconf
datasets
scipy
scikit-learn
wandb

# this is for training, etc
#-e ./OLMo-core[all]

# this is for conversion
#-e ./OLMo-core[all]
#-e ./transformers[torch]

# this is for inference
-e ./FlexOlmo[eval]

# -e ./lm-evaluation-harness

beaker-gantry==1.17.1
smart-open
grouped-gemm # for olmoe
notebook
#dolma # don't include this when sending batch jobs to beaker (too slow)