torch==2.6.0
omegaconf
datasets
scipy
scikit-learn
wandb

# this is for running evals and training, etc
-e ./OLMo-core[all]
-e ./FlexOlmo[eval]
transformers@git+https://github.com/2015aroras/transformers@shanea/olmoe2


# this is for conversion
#-e ./OLMo-core[all]
#-e ./transformers[torch]

# -e ./lm-evaluation-harness

beaker-gantry==1.17.1
smart-open
grouped-gemm # for olmoe
notebook
#dolma # don't include this when sending batch jobs to beaker (too slow)